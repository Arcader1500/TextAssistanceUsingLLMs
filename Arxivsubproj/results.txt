Query: What is the Assessment Misalignment problem in Large Language Models?


--- Retrieved Context ---
Content [[[1]]]
: and a certain search overhead. Although our detached alignment loss can mitigate the assessment
misalignment problem without requiring any hyper-parameters, it sometimes falls short in comparison
to the boundary constraint alignment loss, especially in ranking situations. Therefore, how to design
a dynamic boundary constraint without introducing the hyper-parameter is a meaningful question,
which leaves for further work.
REFERENCES
Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal, Dinesh Khandelwal, Parag Singla,
and Dinesh Garg. Explanations for CommonsenseQA: New Dataset and Models. In Proceed-
ings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th
International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp.
3050–3065, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/
2021.acl-long.238. URL https://aclanthology.org/2021.acl-long.238.
Content [[[2]]]
: arXiv preprint arXiv:2210.13312, 2022.
Shi, Z., Wang, Z., Fan, H., Zhang, Z., Li, L., Zhang, Y .,
Yin, Z., Sheng, L., Qiao, Y ., and Shao, J. Assessment
of multimodal large language models in alignment with
human values. arXiv preprint arXiv:2403.17830, 2024.
Sun, L., Huang, Y ., Wang, H., Wu, S., Zhang, Q., Gao, C.,
Huang, Y ., Lyu, W., Zhang, Y ., Li, X., et al. Trustllm:
Trustworthiness in large language models. arXiv preprint
arXiv:2401.05561, 2024.
Sun, X., Li, X., Li, J., Wu, F., Guo, S., Zhang, T.,
and Wang, G. Text classification via large language
models. In Conference on Empirical Methods in
Natural Language Processing , 2023. URL https:
7
Content [[[3]]]
: Preprint
MAKING LARGE LANGUAGE MODELS BETTER REA-
SONERS WITH ALIGNMENT
Peiyi Wang1 Lei Li3 Liang Chen1 Feifan Song1
Binghuai Lin2 Yunbo Cao2 Tianyu Liu2 Zhifang Sui1
1 National Key Laboratory for Multimedia Information Processing, Peking University
2 Tencent Cloud AI
3 The University of Hong Kong
{wangpeiyi9979, nlp.lilei}@gmail.com
leo.liang.chen@outlook.com; songff@stu.pku.edu.cn
{binghuailin, yunbocao, rogertyliu}@tencent.com; szf@pku.edu.cn
ABSTRACT
Reasoning is a cognitive process of using evidence to reach a sound conclusion.
The reasoning capability is essential for large language models (LLMs) to serve
as the brain of the artificial general intelligence agent. Recent studies reveal that
fine-tuning LLMs on data with the chain of thought (COT) reasoning process
can significantly enhance their reasoning capabilities. However, we find that the
fine-tuned LLMs suffer from an Assessment Misalignment problem, i.e., they
Content [[[4]]]
: Large Language Models Lack Understanding of Character Composition of W ords
Diao, C., Dour, C., Stinson, C., Argueta, C., Ram’irez,
C. F ., Singh, C., Rathkopf, C., Meng, C., Baral, C., Wu,
C., Callison-Burch, C., W aites, C., V oigt, C., Manning,
C. D., Potts, C., Ramirez, C., Rivera, C., Siro, C., Raf-
fel, C., Ashcraft, C., Garbacea, C., Sileo, D., Garrette,
D. H., Hendrycks, D., Kilman, D., Roth, D., Freeman,
D., Khashabi, D., Levy, D., Gonz’alez, D. M., Perszyk,
D. R., Hernandez, D., Chen, D., Ippolito, D., Gilboa, D.,
Dohan, D., Drakard, D., Jurgens, D., Datta, D., Ganguli,
D., Emelin, D., Kleyko, D., Y uret, D., Chen, D., T am, D.,
Hupkes, D., Misra, D., Buzan, D., Mollo, D. C., Y ang,
D., Lee, D.-H., Schrader, D., Shutova, E., Cubuk, E. D.,
Segal, E., Hagerman, E., Barnes, E., Donoway, E. P .,
Pavlick, E., Rodol` a, E., Lam, E., Chu, E., T ang, E., Er-
dem, E., Chang, E., Chi, E. A., Dyer, E., Jerzak, E., Kim,
E., Manyasi, E. E., Zheltonozhskii, E., Xia, F ., Siar, F .,
Content [[[5]]]
: and vowels).
A.2.2. R E S U LT S
T able
7 summarizes the results across all tasks for each lan-
guage using different LLMs, and T able 8 shows example
failure cases for each language. Considering that humans
with elementary understanding of respective languages can
solve the tasks easily, it is fair to say that all languages pe r-
form poorly across all tasks and models. However, there ex-
ist notable discrepancies among the performances depend-
ing on the language.
First, LLMs performed slightly better on Chinese than in
English throughout the models and tasks, which is notable
since, for most models, English is likely the majority lan-
guage in their training corpora. W e conjecture that this
may be related to the logographic nature of Chinese char-
acter system, where characters are frequently equivalent
to words, eliminating the necessity for the models to un-
derstand the language at different levels. On the contrary,
LLMs’ performances unanimously degraded for Korean



Correct Answer:
The Assessment Misalignment problem refers to the phenomenon where fine-tuned LLMs frequently assign higher scores (lower perplexity) to subpar Chain-of-Thought (COT) reasoning paths compared to high-quality ones, leading to potential limitations in their reasoning abilities.",

Source Paper: "Making Large Language Models Better Reasoners with Alignment"