{
 "cells": [
  {
   "cell_type": "code",
   "id": "a83167d28a72b063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T07:25:55.725213Z",
     "start_time": "2026-01-18T07:25:42.970536Z"
    }
   },
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    Pipeline)\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "# Cleanup\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Configuration\n",
    "DB_PATH = os.path.join(os.getcwd(), \"arxiv\")  # Safe path joining\n",
    "MODEL_ID = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d4d85b764a67dbe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T07:25:59.985774Z",
     "start_time": "2026-01-18T07:25:59.788394Z"
    }
   },
   "source": [
    "# Initialize Client & Embedding\n",
    "client = chromadb.PersistentClient(path=DB_PATH)\n",
    "\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "collection = client.get_or_create_collection(name=\"Arxiv-Database\",\n",
    "                                             embedding_function=embedding_func)\n",
    "\n",
    "def search(query, top_k_retrieval=20, top_k_rerank=5):\n",
    "\n",
    "    # Stage 1: Semantic Retrieval (Bio-Encoder)\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k_retrieval\n",
    "    )\n",
    "    \n",
    "    documents = results['documents'][0]\n",
    "    metadatas = results['metadatas'][0]\n",
    "    \n",
    "    # Stage 2: Re-ranking (Cross-Encoder)\n",
    "    # Prepare pairs: (Query, Document_Context)\n",
    "    pairs = [[query, doc] for doc in documents]\n",
    "    \n",
    "    # Predict scores\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    \n",
    "    # Stage 3: Return top-k results\n",
    "    retrieved = []\n",
    "    for rank, idx in enumerate(ranked_indices[:top_k_rerank]):\n",
    "        retrieved.append({\n",
    "            \"rank\": rank+1,\n",
    "            \"score\": scores[idx],\n",
    "            \"source\": metadatas[idx]['source'],\n",
    "            \"page\": metadatas[idx]['page'],\n",
    "            \"content\": documents[idx]\n",
    "        })\n",
    "\n",
    "    return retrieved\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6cf7e96393738f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T07:26:54.028404Z",
     "start_time": "2026-01-18T07:26:01.982827Z"
    }
   },
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    # device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "print(\"⏳ Loading Cross-Encoder Model...\")\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "print(\"✅ Cross-Encoder Loaded.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading Cross-Encoder Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfefbfc303be4c609e0c7976acf065cd"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17ae4a56511f49fd9f1bb16261288987"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "445a972562744171ba94f7c60393f8b9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5afd89d231847199cb218d46c6201de"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d261a45b87d417494b49df46ec8a36c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45b7be9658aa48cda8f48b7d6e89001f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d2675f954f3462aadc4096094a4a564"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross-Encoder Loaded.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "b1f358ef76bac712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T07:28:13.355362Z",
     "start_time": "2026-01-18T07:28:11.516429Z"
    }
   },
   "source": [
    "query = \"What is the Assessment Misalignment problem in Large Language Models?\"\n",
    "docs = search(query)\n",
    "\n",
    "print(\"--- Retrieved Context ---\")\n",
    "for doc in docs:\n",
    "    print(f\"Content \\n: {doc['content']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieved Context ---\n",
      "Content \n",
      ": and a certain search overhead. Although our detached alignment loss can mitigate the assessment\n",
      "misalignment problem without requiring any hyper-parameters, it sometimes falls short in comparison\n",
      "to the boundary constraint alignment loss, especially in ranking situations. Therefore, how to design\n",
      "a dynamic boundary constraint without introducing the hyper-parameter is a meaningful question,\n",
      "which leaves for further work.\n",
      "REFERENCES\n",
      "Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal, Dinesh Khandelwal, Parag Singla,\n",
      "and Dinesh Garg. Explanations for CommonsenseQA: New Dataset and Models. In Proceed-\n",
      "ings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th\n",
      "International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp.\n",
      "3050–3065, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/\n",
      "2021.acl-long.238. URL https://aclanthology.org/2021.acl-long.238.\n",
      "Content \n",
      ": the reasoning ability of LLMs by alleviating the assessment misalignment problem caused by VFT.\n",
      "To address the assessment misalignment problem, in this paper, we propose an alignment fine-tuning\n",
      "(AFT) paradigm to improve LLM reasoning with three steps: 1) fine-tuning LLMs using COT\n",
      "training data; 2) generating multiple COT responses for each question using the fine-tuned LLMs,\n",
      "and categorizing them as positive and negative based on whether they deduce the correct answer;\n",
      "3) calibrating the scores of positive and negative responses given by LLMs with a novel constraint\n",
      "alignment (CA) loss. Specifically, the CA loss ensures that all positive scores (the scores of positive\n",
      "COTs) are larger than negative scores. In addition, the negative scores are protected by a constraint\n",
      "term, which is proven to be very important in preventing model degradation. Beyond just binary\n",
      "positive and negative feedback, the CA loss can be seamlessly adapted to ranking situations when\n",
      "Content \n",
      ": fine-tuned LLMs suffer from an Assessment Misalignment problem, i.e., they\n",
      "frequently assign higher scores to subpar COTs, leading to potential limitations\n",
      "in their reasoning abilities. To address this problem, we introduce an Alignment\n",
      "Fine-Tuning (AFT)paradigm, which involves three steps: 1) fine-tuning LLMs with\n",
      "COT training data; 2) generating multiple COT responses for each question, and\n",
      "categorizing them into positive and negative ones based on whether they achieve\n",
      "the correct answer; 3) calibrating the scores of positive and negative responses\n",
      "given by LLMs with a novel constraint alignment loss. Specifically, the constraint\n",
      "alignment loss has two objectives: a) Alignment, which guarantees that positive\n",
      "scores surpass negative scores to encourage answers with high-quality COTs;\n",
      "b) Constraint, which keeps the negative scores confined to a reasonable range\n",
      "to prevent the model degradation. Beyond just the binary positive and negative\n",
      "Content \n",
      ": Preprint\n",
      "indicate that AFT not only improves the performance of in-distribution tasks but also enhances the\n",
      "model’s transfer ability, leading to significantly better out-of-distribution performance.\n",
      "7 C ONCLUSION\n",
      "In this paper, we find that the vanilla fine-tuned (VFT) LLMs with chain-of-thought (COT) reasoning\n",
      "process suffer from an assessment misalignment problem, i.e, they fail to access the quality of different\n",
      "COTs of the learned questions, which hinders the reasoning ability of LLMs. To this end, we propose\n",
      "an alignment fine-tuning (AFT) paradigm. Our AFT consists of a novel constraint alignment loss that\n",
      "can align the model assessment behaviors without harming the model performance. Furthermore, we\n",
      "also delve deeply into recent widely used ranking losses for alignment and find that the constraint,\n",
      "which has been overlooked by these approaches, is also crucial for their performance. Extensive\n",
      "Content \n",
      ": correct answer. In this paper, we find that previous vanilla fine-tuning (VFT) paradigm causes LLMs\n",
      "to suffer from an Assessment Misalignment problem, i.e., LLMs struggle with accessing the quality\n",
      "1\n",
      "arXiv:2309.02144v1  [cs.CL]  5 Sep 2023\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40df56bf198a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
